#!/usr/bin/env python3
"""
genQA_pair/gen_qa.py

Generate QA pairs from legal regulation Markdown files using Gemini API.
Utilises Context Caching to avoid re-uploading the system prompt + full
document on every run, saving input token costs significantly.

Usage:
  python genQA_pair/gen_qa.py --list
  python genQA_pair/gen_qa.py --md_file <filename.md>
  python genQA_pair/gen_qa.py --md_file <filename.md> --runs 5
"""

import argparse
import json
import os
import re
import sys
import time
from pathlib import Path

from dotenv import load_dotenv
from google import genai
from google.genai import types

# â”€â”€â”€ Paths â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ROOT_DIR = Path(__file__).resolve().parent.parent
PROCESSED_DIR = ROOT_DIR / "processed_data"
OUTPUT_DIR = ROOT_DIR / "genQA_pair"

# â”€â”€â”€ Gemini Model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
MODEL = "gemini-2.5-flash-lite"

# â”€â”€â”€ System Instruction (Design Matrix) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
SYSTEM_INSTRUCTION = """ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„æ³•è¦ QA è³‡æ–™é›†ç”ŸæˆåŠ©ç†ï¼Œå°ˆé–€ç‚º TAIDE å¤§å‹èªè¨€æ¨¡å‹çš„å¾®èª¿è¨“ç·´ç”¢è£½é«˜å“è³ªçš„æ³•è¦å•ç­”å°ï¼ˆQA Pairsï¼‰ã€‚

## æ ¸å¿ƒè¨­è¨ˆæ¨™æº–çŸ©é™£

### ä»»å‹™ä¸€ï¼šæ³•è¦è‰æ“¬ï¼ˆDraftingï¼‰

**Input è®Šç•°è¦å‰‡ï¼ˆä¸‰ç¨®å‹æ…‹è¼ªæµä½¿ç”¨ï¼Œé¿å…é‡è¤‡ï¼‰ï¼š**

1. **ç™½è©±æ–‡å£è¿°å‹**ï¼šæ¨¡æ“¬é•·å®˜å£é ­äº¤è¾¦çš„èªæ°£ã€‚
   - ç¯„ä¾‹æ ¼å¼ï¼šã€Œå¹«æˆ‘å¯«ä¸€æ®µ [ä¸»é¡Œ] çš„æ¢æ–‡ï¼Œèªªæ˜ [éœ€æ±‚ç´°ç¯€]ã€‚ã€

2. **æ¢åˆ—é‡é»å‹**ï¼šæ¨¡æ“¬æ‰¿è¾¦äººæ•´ç†çš„æ¥­å‹™åˆ†å·¥è‰ç¨¿ã€‚
   - ç¯„ä¾‹æ ¼å¼ï¼šã€Œ[å–®ä½A] è² è²¬ [è·èƒ½1]ã€‚[å–®ä½B] è² è²¬ [è·èƒ½2]ã€‚è«‹æ“šæ­¤è‰æ“¬æ¢æ–‡ã€‚ã€

3. **å±€éƒ¨æ“´å¯«å‹**ï¼šçµ¦å®šåè©æˆ–æ¦‚å¿µï¼Œè¦æ±‚æ“´å¯«æˆæ¨™æº–æ¢æ–‡ã€‚
   - ç¯„ä¾‹æ ¼å¼ï¼šã€Œè«‹å°‡ä»¥ä¸‹åè©æ“´å¯«ç‚ºæœ¬è¦å®šçš„åè©å®šç¾©æ¢æ–‡ï¼š[åè©]ã€

**Output æ¨™æº–ï¼ˆå¿…é ˆåš´æ ¼éµå®ˆï¼‰ï¼š**
- 100% é‚„åŸæ³•è¦åŸæ–‡çš„å±¤ç´šç¬¦è™Ÿï¼šç·¨ï¼ˆç¯‡ï¼‰â†’ æ¢ï¼ˆä¸€ã€äºŒã€ä¸‰â€¦ï¼‰â†’ æ¬¾ï¼ˆï¼ˆä¸€ï¼‰ï¼ˆäºŒï¼‰â€¦ï¼‰â†’ ç›®ï¼ˆ1. 2. 3.â€¦ï¼‰
- ç²¾æº–ä½¿ç”¨ä¾†æºæ–‡ä»¶çš„å°ˆå±¬æ©Ÿé—œåç¨±ã€è¡“èªï¼Œä¸å¾—è‡ªè¡Œæ›¿æ›ï¼ˆä¾‹å¦‚ï¼šã€Œå…¬å…±é—œä¿‚å®¤ï¼ˆå“¡å”ä¸­å¿ƒï¼‰ã€ä¸å¯å¯«æˆã€Œå…¬é—œéƒ¨ã€ï¼‰
- output å¿…é ˆæ˜¯å®Œæ•´çš„æ³•è¦æ¢æ–‡æ ¼å¼

---

### ä»»å‹™äºŒï¼šæ³•è¦å¯©æŸ¥ï¼ˆReviewï¼‰

**éŒ¯èª¤æ³¨å…¥ï¼ˆError Injectionï¼‰è¦å‰‡ï¼ˆå¿…é ˆåœ¨ input ä¸­æ•…æ„æ¤å…¥ä¸‹åˆ—ä¸€ç¨®æˆ–å¤šç¨®éŒ¯èª¤ï¼‰ï¼š**

1. **å±¤ç´šç¬¦è™ŸéŒ¯èª¤**ï¼šå°‡ã€Œï¼ˆä¸€ï¼‰ã€å¯«æˆã€Œ1.ã€ï¼›å°‡ã€Œä¸€ã€ã€å¯«æˆã€Œç¬¬ä¸€æ¢ã€ï¼›å°‡ã€Œç¬¬Xç·¨ã€å¯«æˆã€Œç¬¬Xç« ã€
2. **å–®ä½åç¨±éŒ¯èª¤**ï¼šå°‡æ­£ç¢ºçš„æ©Ÿé—œæˆ–å–®ä½åç¨±æ•…æ„æ›¿æ›æˆéŒ¯èª¤åç¨±
   - ä¾‹å¦‚ï¼šã€Œå…¬å…±é—œä¿‚å®¤ï¼ˆå“¡å”ä¸­å¿ƒï¼‰ã€â†’ã€Œå…¬é—œéƒ¨ã€ï¼›ã€ŒäººåŠ›è³‡æºè™•ã€â†’ã€Œäººäº‹å®¤ã€ï¼›ã€Œå·¥å®‰è¡›ç”Ÿå®¤ã€â†’ã€Œå®‰è¡›ç§‘ã€
3. **å°ˆæ¥­è¡“èªï¼æ•¸å€¼ç«„æ”¹**ï¼šå°‡é‡è¡¨åˆ†æ•¸ã€æ³•å®šé–€æª»å€¼ã€æ™‚é–“æœŸé™ç­‰é—œéµæ•¸å€¼æ•…æ„æ”¹éŒ¯
4. **é«”ä¾‹æ¶æ§‹éºæ¼**ï¼šæ•…æ„åˆªé™¤æŸæ®µè½ä¸­çš„ã€Œç›®çš„ã€ã€ã€Œåè©å®šç¾©ã€æˆ–ã€Œé©ç”¨å°è±¡ã€ç­‰å¿…è¦æ¢ç›®

**Output æ¨™æº–ï¼ˆå¿…é ˆåš´æ ¼éµå®ˆï¼‰ï¼š**
- ã€ç›´æ¥å»ºè­°ã€‘ï¼šåˆ—é»èªªæ˜æ¯è™•å…·é«”ä¿®æ­£å»ºè­°ï¼ˆåŸæ–‡â†’æ‡‰æ”¹ç‚ºï¼‰
- ã€åŸå› èªªæ˜ã€‘ï¼šé€é»è§£é‡‹éŒ¯èª¤åŸå› 
- ã€æ³•è¦ä¾æ“šã€‘ï¼šæŒ‡å‡ºé•åçš„é«”ä¾‹è¦å®šæˆ–å¯¦è³ªè¦å®š

---

## è¼¸å‡ºæ ¼å¼ï¼ˆåš´æ ¼éµå®ˆï¼‰

å›å‚³ä¸€å€‹åˆæ³•çš„ JSON ç‰©ä»¶ï¼Œä¸å¾—æœ‰ä»»ä½• markdown code fenceï¼ˆä¸è¦æœ‰ ```jsonï¼‰ã€ä¸å¾—æœ‰å‰å°èªªæ˜æ–‡å­—ï¼Œç›´æ¥ä»¥ `{` é–‹é ­ï¼Œçµæ§‹å¦‚ä¸‹ï¼š

{
  "qa_pairs": [
    {
      "task_type": "drafting",
      "meta_info": {
        "source_document": "<ä¾†æºæ–‡ä»¶æª”å>",
        "source_article": "<å°æ‡‰çš„æ¢æ¬¡æˆ–æ¨™é¡Œï¼Œä¾‹å¦‚ï¼šäº”ã€æ¬Šè²¬å€åˆ†>",
        "generation_strategy": "<èªªæ˜æœ¬é¡Œå¦‚ä½•è¨­è¨ˆ inputï¼Œä½¿ç”¨äº†å“ªç¨®è®Šç•°å‹æ…‹>"
      },
      "training_data": {
        "instruction": "<çµ¦ TAIDE çš„è§’è‰²æ‰®æ¼”æŒ‡ä»¤>",
        "input": "<è‰æ“¬ä»»å‹™çš„ä½¿ç”¨è€…è¼¸å…¥ï¼Œæ¨¡æ“¬å£è¿°ï¼æ¢åˆ—ï¼æ“´å¯«çš„æ¥­å‹™éœ€æ±‚>",
        "output": "<ç¬¦åˆæ³•åˆ¶é«”ä¾‹çš„å®Œæ•´æ¨™æº–æ¢æ–‡>"
      }
    },
    {
      "task_type": "review",
      "meta_info": {
        "source_document": "<ä¾†æºæ–‡ä»¶æª”å>",
        "source_article": "<å°æ‡‰çš„æ¢æ¬¡æˆ–æ¨™é¡Œ>",
        "error_injected": "<æ¢åˆ—èªªæ˜æ¤å…¥äº†å“ªäº›éŒ¯èª¤ï¼Œä»¥åŠæ­£ç¢ºç­”æ¡ˆ>"
      },
      "training_data": {
        "instruction": "<çµ¦ TAIDE çš„è§’è‰²æ‰®æ¼”æŒ‡ä»¤>",
        "input": "<å«æœ‰æ•…æ„éŒ¯èª¤çš„æ³•è¦è‰æ¡ˆç‰‡æ®µ>",
        "output": "<å«ã€ç›´æ¥å»ºè­°ã€‘ã€åŸå› èªªæ˜ã€‘ã€æ³•è¦ä¾æ“šã€‘ä¸‰æ®µçš„æ¨™æº–å¯©æŸ¥æ„è¦‹>"
      }
    }
  ]
}
"""

# â”€â”€â”€ Few-shot Example â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
FEW_SHOT_EXAMPLE = """ä»¥ä¸‹æ˜¯å…©ç­†æ¨™æº–ç¯„ä¾‹ï¼Œä¾›ä½ å°ç…§è¼¸å‡ºæ ¼å¼èˆ‡å“è³ªæ¨™æº–ï¼š

=== ç¯„ä¾‹ 1ï¼šdrafting ===
{
  "task_type": "drafting",
  "meta_info": {
    "source_document": "åœ‹å®¶ä¸­å±±ç§‘å­¸ç ”ç©¶é™¢å“¡å·¥å¿ƒç†å¥åº·ä½œæ¥­è¦å®šè‰æ¡ˆ.md",
    "source_article": "äº”ã€æ¬Šè²¬å€åˆ†",
    "generation_strategy": "æ¢åˆ—é‡é»å‹ï¼šæä¾›å››å€‹å–®ä½çš„æ¥­å‹™åˆ†å·¥é‡é»ï¼Œè¦æ±‚è‰æ“¬å®Œæ•´çš„æ¬Šè²¬å€åˆ†æ¢æ–‡ï¼Œæ¸¬è©¦å–®ä½åç¨±èˆ‡æ³•åˆ¶ä½œæ¥­ç”¨èªï¼ˆå¦‚ï¼šå‰¯çŸ¥ã€å”è™•ï¼‰ã€‚"
  },
  "training_data": {
    "instruction": "ä½ æ˜¯ä¸€ä½ä¸­ç§‘é™¢çš„æ³•è¦è‰æ“¬åŠ©ç†ã€‚è«‹æ ¹æ“šä½¿ç”¨è€…æä¾›çš„æ¥­å‹™éœ€æ±‚ï¼Œä¾æ“šæœ¬é™¢æ³•è¦é«”ä¾‹æ ¼å¼è‰æ“¬å°æ‡‰çš„æ³•è¦æ¢æ–‡ã€‚",
    "input": "æˆ‘å€‘ç¾åœ¨è¦å¾‹å®šå“¡å·¥å¿ƒç†å¥åº·çš„æ¬Šè²¬å€åˆ†ã€‚ç¸½å…±åˆ†å››å€‹å–®ä½ï¼šäººè³‡è™•è¦åœ¨ç”„è©¦æ™‚æŒæ¡å“¡å·¥èº«å¿ƒç‹€æ³ï¼›å·¥å®‰è¡›ç”Ÿå®¤è¦åœ¨å·¡æŸ¥æ™‚æ³¨æ„å“¡å·¥ç‹€æ…‹ï¼›é†«å‹™æ‰€é‡åˆ°æœ‰éœ€æ±‚çš„å“¡å·¥è¦å¹«å¿™è½‰ä»‹ï¼›å„ä¸€ç´šå–®ä½ä¸»ç®¡è¦ä¸»å‹•é—œæ‡·å“¡å·¥ä¸¦è¦–éœ€è¦è½‰ä»‹çµ¦å…¬é—œå®¤ã€‚è«‹å¹«æˆ‘è‰æ“¬é€™éƒ¨åˆ†çš„æ¢æ–‡ã€‚",
    "output": "äº”ã€æ¬Šè²¬å€åˆ†ï¼š\nçµåˆäººè³‡ã€å·¥å®‰è¡›ç”Ÿã€é†«ç™‚ã€è¼”å°ç­‰è³‡æºå¹³å°ï¼Œè¼”å°å€‹æ¡ˆæˆ–è½‰ä»‹è‡³å°ˆæ¥­å¿ƒç†è«®å•†æˆ–ç²¾ç¥é†«ç™‚ä¹‹æ©Ÿæ§‹ï¼Œä»¥å”åŠ©åŒä»é©æ‡‰ç”Ÿæ´»ã€ç¶­è­·èº«å¿ƒå¥åº·ï¼Œç‡Ÿé€ äº’å‹•è‰¯å¥½ä¹‹å‹å–„è·å ´ã€‚\nï¼ˆä¸€ï¼‰äººåŠ›è³‡æºè™•ï¼šæ–¼ç”„è©¦ä½œæ¥­åŠäººå“¡è©¦ç”¨éšæ®µï¼Œä¾æœ¬é™¢ç›¸é—œè¦å®šé¸ã€è¨“ã€ç”¨ã€æ±°ã€ç•™ç­‰ä½œæ³•ï¼Œè¨‚å®šèª å¯¦æ¢æ¬¾ï¼ŒæŒæ¡å“¡å·¥èº«å¿ƒç‹€æ³æ¬ ä½³è€…ï¼Œå‰¯çŸ¥ç”¨äººç®¡ç†å–®ä½ä¸¦å”åŠ©å®Œæˆè¨“ç·´ã€ä»»ç”¨ã€è€ƒæ ¸ã€æ±°ç•™ç­‰æ©Ÿåˆ¶ã€‚\nï¼ˆäºŒï¼‰å·¥å®‰è¡›ç”Ÿå®¤ï¼šè—‰å¹³æ—¥å®šæœŸå·¥å®‰å·¡æŸ¥æ™‚æ©Ÿï¼Œå”åŠ©æŒæ¡ã€ç™¼æ˜å“¡å·¥èº«å¿ƒå¥åº·ç‹€æ…‹ï¼ŒæŸ¥å¯Ÿå“¡å·¥æ˜¯å¦å½±éŸ¿å·¥å®‰ä¹‹å¿ƒç†å¥åº·å› ç´ ï¼Œç¢ºç¶­è·å ´å®‰å…¨ã€‚\nï¼ˆä¸‰ï¼‰é†«å‹™æ‰€ï¼šå”åŠ©å°±è¨ºå“¡å·¥è©•ä¼°å¿ƒç†ç‹€æ³å¾Œï¼Œæœ‰å¿ƒç†è¼”å°éœ€æ±‚æ™‚ï¼Œæ‡‰å¾µå¾—ç•¶äº‹äººåŒæ„å¾Œè—‰ç”±é™¢å…§æ©Ÿåˆ¶ï¼Œå”è«‹å–®ä½æˆ–è½‰ä»‹å°ˆæ¥­å¿ƒè¼”äººå“¡å”è™•ã€‚\nï¼ˆå››ï¼‰å„ä¸€ç´šå–®ä½ï¼š\n1. å–®ä½ä¸»ç®¡æ‡‰æŒ‡å°æ‰€å±¬äºŒç´šä¸»ç®¡å¾äº‹åˆç´šé é˜²å·¥ä½œä¹‹æ¨å±•ï¼Œä¸¦è¦–å“¡å·¥è­°é¡Œéœ€æ±‚è½‰ä»‹å…¬å…±é—œä¿‚å®¤(å“¡å”ä¸­å¿ƒ)å”è™•ã€‚\n2. å°å–®ä½å…§å“¡å·¥æœ‰èº«å¿ƒå›°æ“¾æˆ–å®¶åº­æœ‰é‡å¤§è®Šæ•…å½±éŸ¿å·¥ä½œé‚è¡Œæ™‚ï¼Œæ‡‰ä¸»å‹•ç­è§£åŠç©©å®šå“¡å·¥å¿ƒç·’ï¼Œäºˆä»¥é—œæ‡·å¦¥è™•ï¼Œä¸¦è¦–éœ€è¦è½‰ä»‹å…¬å…±é—œä¿‚å®¤(å“¡å”ä¸­å¿ƒ)è¼”å°ã€‚"
  }
}

=== ç¯„ä¾‹ 2ï¼šreview ===
{
  "task_type": "review",
  "meta_info": {
    "source_document": "åœ‹å®¶ä¸­å±±ç§‘å­¸ç ”ç©¶é™¢å“¡å·¥å¿ƒç†å¥åº·ä½œæ¥­è¦å®šè‰æ¡ˆ.md",
    "source_article": "åäºŒã€åŸ·è¡Œä½œæ³•ï¼ˆå€‹æ¡ˆåˆ†é¡åŠè¼”å°æ¬Šè²¬ï¼‰",
    "error_injected": "1. æ¢æ¬¡ç·¨æ’éŒ¯èª¤ï¼ˆã€ŒåäºŒã€ã€å¯«æˆã€Œç¬¬åäºŒæ¢ã€ï¼‰ã€‚2. BSRS-5é‡è¡¨Cç´šå€‹æ¡ˆåˆ†æ•¸å¯«éŒ¯ï¼ˆæ‡‰ç‚ºã€Œåè‡³åäº”åˆ†ã€ï¼Œèª¤æ¤ç‚ºã€Œäº”è‡³ååˆ†ã€ï¼‰ã€‚3. å–®ä½åç¨±éŒ¯èª¤ï¼ˆã€Œå…¬å…±é—œä¿‚å®¤(å“¡å”ä¸­å¿ƒ)ã€å¯«æˆã€Œå…¬é—œéƒ¨ã€ï¼‰ã€‚"
  },
  "training_data": {
    "instruction": "ä½ æ˜¯ä¸€ä½ä¸­ç§‘é™¢çš„æ³•è¦å¯©æŸ¥åŠ©ç†ã€‚è«‹æª¢è¦–ä»¥ä¸‹æ³•è¦è‰æ¡ˆç‰‡æ®µï¼Œæ¨™è¨»éŒ¯æ¼ä¹‹è™•ï¼Œä¸¦æä¾›ç¬¦åˆæœ¬é™¢é«”ä¾‹çš„ä¿®æ­£å»ºè­°ã€‚",
    "input": "è«‹å¹«æˆ‘å¯©æŸ¥é€™æ®µè¼”å°æ¬Šè²¬çš„è‰æ¡ˆï¼š\n\nç¬¬åäºŒæ¢\n(äºŒ) å€‹æ¡ˆåˆ†é¡åŠè¼”å°æ¬Šè²¬ï¼š\n1. å€‹æ¡ˆåˆ†é¡:\n(3)Cç´šï¼šæ–°é€²é©æ‡‰ä¸ä½³ã€ç”Ÿæ´»å›°æ“¾ã€å®¶åº­åŠæ„Ÿæƒ…å›°æ“¾ã€BSRS-5é‡è¡¨äº”è‡³ååˆ†ä¹‹ä¸€èˆ¬å€‹æ¡ˆã€‚\n2. è¼”å°æ¬Šè²¬ï¼š\n(3)Cç´šå€‹æ¡ˆç”±å„å–®ä½è‡ªè¡Œè¼”å°ç®¡ç†ï¼Œä¸¦è¦–éœ€æ±‚æˆ–å€‹æ¡ˆæ„é¡˜è½‰ä»‹å…¬é—œéƒ¨è¼”å°ã€‚",
    "output": "ã€ç›´æ¥å»ºè­°ã€‘ï¼š\n1. å»ºè­°å°‡ã€Œç¬¬åäºŒæ¢ã€ä¿®æ­£ç‚ºã€ŒåäºŒã€åŸ·è¡Œä½œæ³•ï¼šã€ã€‚\n2. å»ºè­°å°‡å€‹æ¡ˆåˆ†é¡Cç´šä¹‹å…§å®¹ä¿®æ­£ç‚ºã€ŒBSRS-5é‡è¡¨åè‡³åäº”åˆ†ä¹‹ä¸€èˆ¬å€‹æ¡ˆã€ã€‚\n3. å»ºè­°å°‡è¼”å°æ¬Šè²¬ä¹‹è½‰ä»‹å–®ä½ä¿®æ­£ç‚ºã€Œå…¬å…±é—œä¿‚å®¤(å“¡å”ä¸­å¿ƒ)ã€ã€‚\n\nã€åŸå› èªªæ˜ã€‘ï¼š\n1. åŸè‰æ¡ˆä½¿ç”¨ã€Œç¬¬åäºŒæ¢ã€ä¸ç¬¦æœ¬é™¢é˜¿æ‹‰ä¼¯æ•¸å­—åŠ é “è™Ÿä¹‹æ¢æ¬¡ç·¨æ’é«”ä¾‹ï¼Œä¸”æ¼åˆ—æ¢æ–‡æ¨™é¡Œã€ŒåŸ·è¡Œä½œæ³•ï¼šã€ã€‚\n2. é—œæ–¼Cç´šå€‹æ¡ˆä¹‹BSRS-5é‡è¡¨åˆ†æ•¸å®šç¾©æœ‰èª¤ï¼Œä¾æ¨™æº–æ‡‰ç‚ºåè‡³åäº”åˆ†ã€‚\n3. æœ¬é™¢å»ºåˆ¶å–®ä½åç¨±ç‚ºã€Œå…¬å…±é—œä¿‚å®¤ã€ï¼Œç„¡ã€Œå…¬é—œéƒ¨ã€ä¹‹ç·¨åˆ¶ã€‚\n\nã€æ³•è¦ä¾æ“šã€‘ï¼šé•åæœ¬é™¢æ³•è¦é«”ä¾‹æ ¼å¼ä¸­é—œæ–¼æ¢æ–‡ç·¨è™Ÿé«”ä¾‹ã€å°ˆæœ‰åè©ï¼ˆçµ„ç¹”ç·¨è£åç¨±ï¼‰åŠå¿ƒç†å¥åº·ä½œæ¥­è¦å®šä¹‹å¯¦è³ªå…§å®¹å®šç¾©ã€‚"
  }
}
"""

# â”€â”€â”€ Helpers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def list_md_files() -> list[Path]:
    """Return all .md files under processed_data/."""
    return sorted(PROCESSED_DIR.glob("*.md"))


def load_document(md_file: str) -> tuple[str, Path]:
    """Load document text and return (text, path). Exits if file not found."""
    path = PROCESSED_DIR / md_file
    if not path.exists():
        print(f"âŒ æ‰¾ä¸åˆ°æª”æ¡ˆï¼š{path}")
        print("å¯ç”¨çš„æª”æ¡ˆï¼š")
        for f in list_md_files():
            print(f"  - {f.name}")
        sys.exit(1)
    text = path.read_text(encoding="utf-8")
    return text, path


def estimate_tokens(text: str) -> int:
    """Rough token estimate: ~1.5 Chinese chars per token."""
    return int(len(text) / 1.5)


def get_or_create_cache(
    client: genai.Client,
    display_name: str,
    document_text: str,
) -> tuple[object | None, bool]:
    """
    Try to find an unexpired cache with the given display_name.
    If found, return (cache, True). If not, create a new one and return (cache, False).
    Returns (None, False) if caching fails (e.g. document too short).
    """
    # Check existing caches
    try:
        for cache in client.caches.list():
            if cache.display_name == display_name:
                print(f"â™»ï¸  æ‰¾åˆ°æ—¢æœ‰ cacheï¼š{cache.name}ï¼ˆè¤‡ç”¨ï¼Œç¯€çœ tokenï¼‰")
                return cache, True
    except Exception as e:
        print(f"âš ï¸  åˆ—èˆ‰ cache æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")

    # Build cache contents
    cache_contents = [
        types.Content(
            role="user",
            parts=[
                types.Part(text=FEW_SHOT_EXAMPLE),
                types.Part(text=f"ä»¥ä¸‹æ˜¯å®Œæ•´çš„æ³•è¦æ–‡æœ¬ï¼Œè«‹ä»”ç´°é–±è®€ï¼Œå¾ŒçºŒç”Ÿæˆ QA Pairs æ™‚ä»¥æ­¤ç‚ºå”¯ä¸€ä¾æ“šï¼š\n\n{document_text}"),
            ],
        ),
        types.Content(
            role="model",
            parts=[types.Part(text="å·²å®Œæ•´é–±è®€æ³•è¦æ–‡æœ¬èˆ‡ç¯„ä¾‹ï¼Œæº–å‚™å¥½ä¾è¨­è¨ˆæ¨™æº–ç”Ÿæˆ QA Pairsã€‚")],
        ),
    ]

    try:
        cache = client.caches.create(
            model=MODEL,
            config=types.CreateCachedContentConfig(
                display_name=display_name,
                system_instruction=SYSTEM_INSTRUCTION,
                contents=cache_contents,
                ttl="3600s",
            ),
        )
        print(f"âœ… å·²å»ºç«‹æ–° cacheï¼š{cache.name}")
        return cache, False
    except Exception as e:
        print(f"âš ï¸  å»ºç«‹ cache å¤±æ•—ï¼ˆ{e}ï¼‰ï¼Œæ”¹ç”¨éå¿«å–æ¨¡å¼")
        return None, False


def build_user_turn(doc_name: str, run_index: int, document_text: str, use_cache: bool) -> str:
    """Build the dynamic user message for each generation run."""
    base = (
        f"è«‹æ ¹æ“šä»¥ä¸Šæ³•è¦æ–‡æœ¬ï¼ˆ{doc_name}ï¼‰ï¼Œç”Ÿæˆ 10 ç­† QA Pairsï¼š\n"
        f"- 5 ç­† task_type = \"drafting\"ï¼ˆä¸‰ç¨® input è®Šç•°å‹æ…‹å‡å‹»åˆ†å¸ƒï¼‰\n"
        f"- 5 ç­† task_type = \"review\"ï¼ˆå››ç¨®éŒ¯èª¤æ³¨å…¥æ¨£æ…‹å‡å‹»åˆ†å¸ƒï¼‰\n"
        f"- æ¯ç­†çš„ source_article å¿…é ˆæŒ‡å‘æ–‡ä»¶ä¸­**ä¸åŒ**çš„æ¢æ¬¡æˆ–æ¬¾æ¬¡ï¼ˆé¿å…é‡è¤‡ï¼‰\n"
        f"- æœ¬è¼ªç¼–è™Ÿ {run_index}ï¼Œè«‹å¾æ–‡ä»¶ä¸­**å°šæœªä½¿ç”¨**çš„æ¢æ–‡å–æï¼Œç¢ºä¿å¤šæ¨£æ€§\n"
        f"- ç›´æ¥è¼¸å‡ºç´” JSONï¼Œä»¥ {{ é–‹é ­ï¼Œä¸å¾—æœ‰ä»»ä½•å‰å°æ–‡å­—æˆ– markdown code fence"
    )
    if not use_cache:
        # Non-cached mode: prepend full context
        return (
            f"{FEW_SHOT_EXAMPLE}\n\n"
            f"ä»¥ä¸‹æ˜¯å®Œæ•´çš„æ³•è¦æ–‡æœ¬ï¼š\n\n{document_text}\n\n"
            f"{base}"
        )
    return base


def parse_json_response(raw: str) -> dict:
    """Parse JSON from model response, with fallback regex extraction."""
    raw = raw.strip()
    try:
        return json.loads(raw)
    except json.JSONDecodeError:
        pass

    # Fallback: extract outermost {...}
    match = re.search(r'\{.*\}', raw, re.DOTALL)
    if match:
        try:
            return json.loads(match.group())
        except json.JSONDecodeError:
            pass

    raise ValueError(f"ç„¡æ³•è§£ææ¨¡å‹å›å‚³çš„ JSONï¼ŒåŸå§‹å…§å®¹å‰ 200 å­—ï¼š\n{raw[:200]}")


def append_to_output(output_path: Path, new_pairs: list[dict]) -> int:
    """Append new QA pairs to output JSON file. Returns total count."""
    if output_path.exists():
        existing = json.loads(output_path.read_text(encoding="utf-8"))
        existing_pairs = existing.get("qa_pairs", [])
    else:
        existing_pairs = []

    merged = existing_pairs + new_pairs
    output_path.write_text(
        json.dumps({"qa_pairs": merged}, ensure_ascii=False, indent=2),
        encoding="utf-8",
    )
    return len(merged)


def inject_source_document(pairs: list[dict], doc_name: str) -> list[dict]:
    """Ensure every pair has source_document set correctly."""
    for pair in pairs:
        meta = pair.setdefault("meta_info", {})
        meta["source_document"] = doc_name
    return pairs


# â”€â”€â”€ Main â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def main():
    load_dotenv(ROOT_DIR / ".env")
    api_key = os.getenv("GEMINI_API_KEY")
    if not api_key:
        print("âŒ æ‰¾ä¸åˆ° GEMINI_API_KEYï¼Œè«‹åœ¨å°ˆæ¡ˆæ ¹ç›®éŒ„å»ºç«‹ .env æª”ä¸¦è¨­å®šæ­¤è®Šæ•¸")
        sys.exit(1)

    parser = argparse.ArgumentParser(
        description="å¾æ³•è¦ Markdown ç”Ÿæˆ QA Pairsï¼ˆä½¿ç”¨ Gemini Context Cachingï¼‰"
    )
    parser.add_argument(
        "--md_file",
        type=str,
        help="processed_data/ ä¸‹çš„ .md æª”å",
    )
    parser.add_argument(
        "--runs",
        type=int,
        default=1,
        help="å°åŒä¸€ä»½æ–‡ä»¶é€£çºŒç”Ÿæˆå¹¾è¼ªï¼ˆæ¯è¼ª 10 ç­†ï¼‰ï¼Œé è¨­ 1",
    )
    parser.add_argument(
        "--list",
        action="store_true",
        help="åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„ .md æª”å¾Œé€€å‡º",
    )
    args = parser.parse_args()

    # â”€â”€ --list â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if args.list:
        files = list_md_files()
        if not files:
            print("processed_data/ ä¸‹æ²’æœ‰ä»»ä½• .md æª”")
        else:
            print(f"æ‰¾åˆ° {len(files)} å€‹å¯ç”¨æ³•è¦æ–‡ä»¶ï¼š")
            for f in files:
                print(f"  - {f.name}")
        sys.exit(0)

    # â”€â”€ --md_file required â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if not args.md_file:
        files = list_md_files()
        if not files:
            print("processed_data/ ä¸‹æ²’æœ‰ä»»ä½• .md æª”ï¼Œè«‹å…ˆè½‰æ›æ–‡ä»¶")
            sys.exit(1)
        print("è«‹ä»¥ --md_file æŒ‡å®šè¦è™•ç†çš„æª”æ¡ˆï¼Œå¯ç”¨é¸é …å¦‚ä¸‹ï¼š")
        for f in files:
            print(f"  - {f.name}")
        sys.exit(0)

    # â”€â”€ Load document â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    doc_text, doc_path = load_document(args.md_file)
    doc_name = doc_path.name
    stem = doc_path.stem
    output_path = OUTPUT_DIR / f"{stem}_qa.json"
    OUTPUT_DIR.mkdir(exist_ok=True)

    token_est = estimate_tokens(doc_text)
    print(f"ğŸ“„ æ–‡ä»¶ï¼š{doc_name}")
    print(f"   å­—å…ƒæ•¸ï¼š{len(doc_text):,}ã€€é ä¼° tokenï¼š{token_est:,}")
    print(f"   è¼¸å‡ºï¼š{output_path.relative_to(ROOT_DIR)}")
    print(f"   åŸ·è¡Œè¼ªæ•¸ï¼š{args.runs} è¼ªï¼ˆé è¨ˆç”Ÿæˆ {args.runs * 10} ç­†ï¼‰")
    print()

    # â”€â”€ Init Gemini client â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    client = genai.Client(api_key=api_key)

    # â”€â”€ Context Cache â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    cache_display_name = stem
    cache, cache_reused = get_or_create_cache(client, cache_display_name, doc_text)
    use_cache = cache is not None

    if not use_cache:
        print("ğŸ“ å°‡åœ¨æ¯æ¬¡å‘¼å«ä¸­ç›´æ¥é™„ä¸Šå®Œæ•´æ–‡æœ¬ï¼ˆéå¿«å–æ¨¡å¼ï¼‰")
    print()

    # â”€â”€ Generation loop â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    total_new = 0
    for run in range(1, args.runs + 1):
        print(f"ğŸ”„ ç¬¬ {run}/{args.runs} è¼ªç”Ÿæˆä¸­â€¦")
        user_msg = build_user_turn(doc_name, run, doc_text, use_cache)

        contents = [types.Content(role="user", parts=[types.Part(text=user_msg)])]

        gen_config = types.GenerateContentConfig(
            temperature=0.7,
            response_mime_type="text/plain",
        )
        if use_cache:
            gen_config.cached_content = cache.name

        try:
            response = client.models.generate_content(
                model=MODEL,
                contents=contents,
                config=gen_config,
            )
        except Exception as e:
            print(f"âŒ API å‘¼å«å¤±æ•—ï¼š{e}")
            sys.exit(1)

        # Token usage
        if hasattr(response, "usage_metadata") and response.usage_metadata:
            u = response.usage_metadata
            cached_count = getattr(u, "cached_content_token_count", 0) or 0
            prompt_count = getattr(u, "prompt_token_count", 0) or 0
            output_count = getattr(u, "candidates_token_count", 0) or 0
            print(
                f"   Token ç”¨é‡ â†’ prompt: {prompt_count}  "
                f"cached: {cached_count}  output: {output_count}"
            )

        # Parse response
        raw_text = response.text or ""
        try:
            result = parse_json_response(raw_text)
        except ValueError as e:
            print(f"âŒ {e}")
            sys.exit(1)

        new_pairs = result.get("qa_pairs", [])
        if not new_pairs:
            print("âš ï¸  æ¨¡å‹å›å‚³çš„ qa_pairs ç‚ºç©ºï¼Œè·³éæœ¬è¼ª")
            continue

        new_pairs = inject_source_document(new_pairs, doc_name)
        total = append_to_output(output_path, new_pairs)
        total_new += len(new_pairs)
        print(f"   âœ… æ–°å¢ {len(new_pairs)} ç­†ï¼Œç´¯è¨ˆ {total} ç­†")

        if run < args.runs:
            time.sleep(1)  # é¿å…éå¿«è§¸ç™¼ rate limit

    print()
    print(f"ğŸ‰ å®Œæˆï¼æœ¬æ¬¡å…±æ–°å¢ {total_new} ç­†ï¼Œè¼¸å‡ºæª”æ¡ˆï¼š{output_path.relative_to(ROOT_DIR)}")


if __name__ == "__main__":
    main()
